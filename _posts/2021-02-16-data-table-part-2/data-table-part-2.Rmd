---
title: "Advanced data.table operations"  
description: |
  Things get querysome and querysome.         
author: Erika Duan
date: 02-16-2021
preview: finalplot.png 
categories: 
  - data cleaning  
  - data.table  
  - dplyr
  - R  
output:
  distill::distill_article: 
    toc: true
---

```{r setup, include=FALSE}
# Set up global environment ----------------------------------------------------
knitr::opts_chunk$set(echo=TRUE, results='hide') 
options(scipen=999)
```


# Introduction    

This post is a continuation of [my comparison](https://erikaduan.github.io/posts/2021-01-30-data-table-part-1/) of R `data.table` versus `dplyr` functions. Imagine you have a dataset describing how students are engaging with online courses:

+ Each student has a unique ID.   
+ There are 5 different online platforms, labelled A, B, C, D and E.   
+ Students have the option of taking different courses within the same platform or switching to a different platform.   
+ Platform start dates are recorded when the student starts the first course on a new platform.  
+ Platform end dates are recorded when the student exits a platform.   
+ Course start dates are recorded when the student starts a course.    
+ Course end dates are recorded when the student exits a course.    

**Note:** The code used to create this dataset can be accessed from my github repository [here](https://github.com/erikaduan/R-tips/blob/master/03_blog_posts/2020-04-07_data-table-versus-dplyr/2020-04-07_data-table-versus-dplyr.md).    

```{r, message=FALSE, warning=FALSE}
# Load required packages -------------------------------------------------------  
if (!require("pacman")) install.packages("pacman")
pacman::p_load(here,
               ids, # Generate random IDs
               tidyverse,
               data.table,
               microbenchmark,
               DT)
```

```{r, echo=FALSE}
# Create a function to generate random dates -----------------------------------
create_start_dates <- function(start_date, end_date, n) {
  # Assert requirement for character inputs 
  if(!is.character(start_date) | !is.character(end_date)) {
    stop("Error: start_date and end_date should be written in the format YYYY-mm-dd")
  }
  
  # Convert character inputs into dates
  start_date <- as.Date(start_date, format = "%Y-%m-%d")
  end_date <- as.Date(end_date, format = "%Y-%m-%d")  
  
  # Assert that end_date >= start_date  
  if(end_date < start_date) {
    stop("Error: start_date should be earlier than end_date")
  }
  
  # Generate date vector of random dates between start_date and end_date
  set.seed(111)
  sample(seq(start_date, end_date, by = "day"),
         n,
         replace = T)
}  
```

```{r, echo=FALSE}
# Create a function to populate course_end_dates -------------------------------
add_course_end_date <- function(df, include_n, row) {
  df %>% 
    group_by(join_key) %>% 
    mutate(course_end_date = if_else(n_courses >= include_n & row_number() == row,
                                     course_start_date + course_length,
                                     course_end_date)) %>%
    ungroup()
}
```

```{r, echo=FALSE}
# Create a function to populate course_start_dates -----------------------------
add_course_start_date <- function(df, include_n, row) {
  df %>% 
    group_by(join_key) %>% 
    mutate(course_start_date = if_else(n_courses >= include_n & row_number() == row,
                                       lag(course_end_date),
                                       course_start_date)) %>%
    ungroup()
}
```

```{r, echo=FALSE}
# Create 500000 student enrollments --------------------------------------------
# Create 150000 unique student IDs  
set.seed(111)
students <- random_id(n = 150000,
                      bytes = 4,
                      use_openssl = F) # So set.seed() works  

# Sample student IDs with replacement 500000 times 
id <- sample(students, 500000,
             replace = T) %>%
  sort()

# Simulate 5 platforms with different market shares  
platform <- sample(LETTERS[1:5], 500000,
                   replace = T,
                   prob = c(0.35, 0.05, 0.1, 0.3, 0.2)) 

# Create 20 courses 
all_courses <- c("R_beginner",
                 "R_intermediate",
                 "R_advanced",
                 "Python_beginner",
                 "Python_intermediate",
                 "Python_advanced",
                 "machine_learning",
                 "linear_algebra",
                 "statistics",
                 "UX_design",
                 "website_design",
                 "data_mining",
                 "travel_writing",
                 "bread_baking",
                 "pottery",
                 "poetry_writing",
                 "contemporary_dance",
                 "carpentry",
                 "metal_welding",
                 "fitness_training")  

course <- sample(all_courses, 500000,
                 replace = T)  

# Create student_courses ------------------------------------------------------- 
student_courses <- tibble(index = seq(1, 500000, 1), # index required for downstream joins
                          id,
                          platform,
                          course)
```

```{r, echo=FALSE}
# Create platform_start_date and platform_end_date entries----------------------
# Create join_key   
platform_subset <- student_courses %>%
  select(index, 
         id,
         platform) %>% 
  mutate(join_key = str_c(id, platform, sep = "-")) 

# Create lag_join_key  
platform_subset <- platform_subset %>%
  group_by(id) %>%
  mutate(lag_join_key = lag(join_key, 1)) %>%
  ungroup()  

# Filter rows representing the first course a student takes on a new platform      
platform_subset <- platform_subset %>%
  filter(is.na(lag_join_key) | lag_join_key != join_key)

# Create platform start_dates vector   
start_dates <- create_start_dates(start_date = "2016-01-01",
                                  end_date = "2019-01-01",  
                                  n = nrow(platform_subset))

platform_subset <- platform_subset %>%
  mutate(platform_start_date = start_dates)

# Create platform_end_date as platform_start_date + random platform_length 
set.seed(111)
platform_length <- runif(nrow(platform_subset),
                         min = 9, max = 90) %>%
  floor(.) 

# Round platform_length to a whole number i.e. whole day for date calculations   

platform_subset <- platform_subset %>%
  mutate(platform_end_date = platform_start_date + platform_length)  

# Left join student_course and provider_subset by index-------------------------
platform_subset <- platform_subset %>%
  select(index,
         platform_start_date,
         platform_end_date)     

student_courses <- left_join(student_courses,
                             platform_subset,
                             by = "index")

student_courses <- student_courses %>%
  fill(c(platform_start_date, platform_end_date), 
       .direction = "up") # NA inherits the value above    

student_courses <- student_courses %>%
  select(-index)   
```

```{r, echo=FALSE}
# Create course_start_date and course_end_date entries ------------------------- 
# Sort by id, platform start_date and platform   
student_courses <- student_courses %>%
  arrange(id, 
          platform_start_date,
          platform)

# Split student_courses into one_course and multiple_courses 
# Create join_key 
student_courses <- student_courses %>%
  mutate(platform_length = platform_end_date - platform_start_date,
         join_key = str_c(id, platform_start_date, platform, sep = "-"))

# Create lag_join_key 
student_courses <- student_courses %>%
  group_by(id) %>% 
  mutate(lag_join_key = lag(join_key)) %>%
  ungroup()

# Multiple courses exists when multiple rows share the same join_key  

multiple_courses_id <- student_courses %>%
  count(join_key) %>%
  filter(n > 1) %>%
  pull(join_key)

multiple_courses <- student_courses %>%
  filter(join_key %in% multiple_courses_id)

single_course <- student_courses %>%
  filter(!join_key %in% multiple_courses_id)

# Create course date logic for single_course------------------------------------  
single_course <- single_course %>%
  mutate(course_start_date = platform_start_date,
         course_end_date = platform_end_date) 

# Create course date logic for multiple_courses---------------------------------
# Check maximum number of courses undertaken on the same platform
multiple_courses %>%
  count(join_key) %>% 
  ungroup() %>%
  pull(n) %>%
  max()  
#> [1] 7

# Populate first course_start_date and last course_end_date for all cases ------    
set.seed(111)
multiple_courses <- multiple_courses %>%
  group_by(join_key) %>%
  mutate(n_courses = n(),
         course_start_date = if_else(row_number() == 1, platform_start_date,
                                     NA_real_),
         course_end_date = if_else(row_number() == n(), platform_end_date,
                                   NA_real_),
         course_length = runif(n = n(), min = 1, max = platform_length / n_courses) %>% ceiling()) %>%
  ungroup()

# Populate first course_end_date for all cases ---------------------------------  
multiple_courses <- multiple_courses %>% 
  group_by(join_key) %>% 
  mutate(course_end_date = if_else(!is.na(course_start_date),
                                   course_start_date + course_length,
                                   course_end_date)) %>%
  ungroup()

# Populate second course_start_date when n_courses >= 2 ------------------------
multiple_courses <- add_course_start_date(multiple_courses, include_n = 2, row = 2)

# Populate second course_end_date when n_courses >= 3 --------------------------
multiple_courses <- add_course_end_date(multiple_courses, include_n = 3, row = 2)

# Populate third course_start_date when n_courses >= 3 ------------------------- 
multiple_courses <- add_course_start_date(multiple_courses, include_n = 3, row = 3)

# Populate third course_end_date when n_courses >= 4 ---------------------------
multiple_courses <- add_course_end_date(multiple_courses, include_n = 4, row = 3)

# Populate fourth course_start_date when n_courses >= 4 ------------------------ 
multiple_courses <- add_course_start_date(multiple_courses, include_n = 4, row = 4)

# Populate fourth course_end_date when n_courses >= 5 -------------------------- 
multiple_courses <- add_course_end_date(multiple_courses, include_n = 5, row = 4)

# Populate fifth course_start_date when n_courses >= 5 -------------------------
multiple_courses <- add_course_start_date(multiple_courses, include_n = 5, row = 5)

# Populate fifth course_end_date when n_courses >= 6 --------------------------- 
multiple_courses <- add_course_end_date(multiple_courses, include_n = 6, row = 5)

# Populate sixth course_start_date when n_courses >= 6 ------------------------- 
multiple_courses <- add_course_start_date(multiple_courses, include_n = 6, row = 6)

# Populate sixth course_end_date when n_courses >= 7 --------------------------- 
multiple_courses <- add_course_end_date(multiple_courses, include_n = 7, row = 6)

# Populate seventh course_start_date when n_courses >= 7 ----------------------- 
multiple_courses <- add_course_start_date(multiple_courses, include_n = 7, row = 7)

# Bind all rows and re-order student_courses -----------------------------------    
student_courses <- bind_rows(single_course,
                             multiple_courses)

student_courses <- student_courses %>%
  select(-c(platform_length,
            course_length,
            n_courses,
            join_key,
            lag_join_key))  

student_courses <- student_courses %>%
  arrange(id,
          platform_start_date,
          platform)
```

```{r, echo=FALSE}
# Remove all objects except student_courses ------------------------------------  
rm(list = setdiff(ls(), "student_courses"))
gc()
```

```{r, echo=FALSE} 
# Convert data frame to data.table ---------------------------------------------  
setDT(student_courses)

class(student_courses) 
#> [1] "data.table" "data.frame"  
```

The first 12 rows of the dataset can be examined interactively below.        

```{r, echo=FALSE, results='markup'}
# Examine the first 12 rows of data --------------------------------------------  
student_courses %>%
  head(12) %>%
  datatable(rownames = F,
            options = list(pageLength = 6, dom = 'tip',
                           initComplete = JS(
                             "function(settings, json) {",
                             "$(this.api().table().header()).css({'background-color': '#37ACA1', 'color': '#fff'});",
                             "}")))
```


# Code sequence impact         


## Using `dplyr`     

Imagine that you would like to subset on fitness training courses from platform C and E and then create a column to denote that these were discounted courses.   

In `dplyr`, this can be written as a single query using the `%>%` pipe to separate each individual function.    

```{r, results='markup'}
# Filter and create a new column using dplyr %>% pipes -------------------------    
dplyr_query_1 <- student_courses %>%
  filter(course == "fitness_training",
         platform %in% c("C", "E")) %>%
  mutate(percentage_discount = 5)
```


## Using `data.table`    

In `data.table`, performing these two operations in separate steps or a single step produces different outputs. ^[Performing the two functions in separate steps is equivalent to the `dplyr` approach above.]    

```{r}
# Filter and create a new column using data.table in separate steps ------------  
dt_query_1 <- student_courses[(course == "fitness_training") 
                              & (platform %chin% c("C", "E"))] %>%
  .[, percentage_discount := 5]   

dt_query_1
```

```{r, echo=FALSE, results='markup'}
# Print the first 4 rows -------------------------------------------------------  
# Subset columns which contain "_date"
date_cols <- grep("_date$", colnames(student_courses), value = T)

dt_query_1[1:4, !..date_cols] %>%
  knitr::kable()
```

In `data.table`, applying filtering and a column transformation in a single step retains all dataset rows and only applies the transformation to rows where the filtering condition is `TRUE`.    

```{r}
# Filter and create a new column using data.table in a single step -------------  
dt_query_1_wrong <- student_courses[(course == "fitness_training") 
                                    & (platform %chin% c("C", "E")), 
                                    percentage_discount := 5]
```

```{r, echo=FALSE, results='markup'}
# Print the first 4 rows -------------------------------------------------------  
dt_query_1_wrong[1:4, !..date_cols] %>%
  knitr::kable()  

# Remove percentage_discount for downstream analyses ---------------------------  
student_courses[, percentage_discount := NULL]  
```


## Benchmark data operations   

There is only a slight speed advantage in using `data.table` over `dplyr`, as our operations do not involve sorting or group by operations.       

```{r, echo=FALSE, results='markup'}
# Benchmark dplyr and data.table functions -------------------------------------  
if (!file.exists(here("data", "data-table-benchmarks-2", "query1.rds"))) {
  
  query1 <- microbenchmark(dplyr_query_1_funs = student_courses %>%
                             filter(course == "fitness_training",
                                    platform %in% c("C", "E")) %>%
                             mutate(percentage_discount = 5),
                           dt_query_1_funs = student_courses[(course == "fitness_training") 
                                                             & (platform %chin% c("C", "E"))] %>%
                             .[, percentage_discount := 5],
                           dt_query_1_wrong_funs = student_courses[(course == "fitness_training") 
                                                                   & (platform %chin% c("C", "E")), 
                                                                   percentage_discount := 5]) 
  
  saveRDS(query1, here("data", "data-table-benchmarks-2", "query1.rds"))
}

# Print summary table ----------------------------------------------------------
query1 <- readRDS(here("data", "data-table-benchmarks-2", "query1.rds"))
knitr::kable(summary(query1), caption = "Units: milliseconds")   
```


# Aggregate by group          

A simple introduction to group by operations is covered [here](https://erikaduan.github.io/posts/2021-01-30-data-table-part-1/#simple-group-by-operations). This post further explores how different outputs can be obtained by modifying `data.table` group by operations in different ways.   

Imagine that you are interested in the total number of days each student has spent on an online platform. Could you obtain this by grouping on `id` and summing the total number of days spent on a platform? 


## Using `dplyr`  

```{r}
# Calculate total platform_length per student using dplyr ----------------------  
student_courses <- student_courses %>%
  mutate(platform_length = platform_end_date - platform_start_date,
         platform_length = as.integer(platform_length)) 

dplyr_query_2 <- student_courses %>%
  group_by(id) %>%
  summarise(total_days = sum(platform_length),
            min_days = min(platform_length),
            median_days = median(platform_length),  
            max_days = max(platform_length)) %>%
  ungroup()    
```

**Note:** In `dplyr`, group by operations should be closed using `ungroup()` to remove object metadata marking row groupings.   


## Using `data.table`   

In `data.table`, you can choose which variable(s) to group by using `by` or `keyby`. The effect of `keyby` is that it also orders the results and creates a secondary key for faster subsequent subsetting.   

```{r}
# Calculate total platform_length per student using data.table ----------------- 
dt_query_2 <- student_courses[, 
                              .(total_days = sum(platform_length),
                                min_days = min(platform_length),
                                median_days = median(platform_length),  
                                max_days = max(platform_length)),
                              by = id]
```

However, this approach overestimates the total number of days spent on an online platform per student, as some students take multiple courses on the same platform. This means that the platform dwell length contains duplicate values that need to be removed.   


# Identify duplicate rows      

You can identify duplicate rows by concatenating `id`, `platform` and `platform_start_date` and counting the total number of rows per concatenation.     


## Using `dplyr`    

```{r}
# Identify duplicate rows using dplyr ------------------------------------------ 
student_courses %>%
  mutate(platform_key = str_c(id, platform, platform_start_date, sep = "-")) %>%
  count(platform_key, name = "row_number") %>%
  count(row_number, name = "total_students")
```


## Using `data.table`    

In `data.table`, `.SD` means 'subset of data' and is used to reference the current sub-table of interest (this is usually a sub-table series that has been split by the `by` operator).     

```{r}
# Identify duplicate rows using dplyr using data.table -------------------------  
student_courses[,
                platform_key := do.call(str_c, c(.SD, sep = "-")),
                .SDcols = c("id", "platform", "platform_start_date")] %>%
  .[, 
    .N,
    by = platform_key] %>% 
  .[,
    .N,
    keyby = N] # Use keyby as we also want to sort by N  
```

**Note:** The base R function `do.call()` constructs and executes a function call from a name or function and a list of function arguments.    


# Remove duplicate rows and aggregate by group    

Knowing that duplicate `platform_length` records exist, a two-step process would be needed to extract the total number of days each student has spent on an online platform:            

+ First, group by `id`, `platform`, `platform_start_date` and extract the first row of each group.     
+ Next, group by `id` and summarise `platform_length` calculations.    


## Using `dplyr`    

```{r}
# Calculate total platform_length per student using dplyr ---------------------- 
dplyr_query_3 <- student_courses %>%
  group_by(id, platform, platform_start_date) %>%
  filter(row_number() == 1L) %>%
  ungroup() %>%
  group_by(id) %>%  
  summarise(total_days = sum(platform_length),
            min_days = min(platform_length),
            median_days = median(platform_length),  
            max_days = max(platform_length)) %>%
  ungroup()

summary(dplyr_query_2 == dplyr_query_3)
#>     id          total_days       min_days       median_days      max_days      
#>  Mode:logical   Mode :logical   Mode :logical   Mode :logical   Mode :logical  
#>  TRUE:144676    FALSE:14674     FALSE:22        FALSE:9745      FALSE:24       
#>                 TRUE :130002    TRUE :144654    TRUE :134931    TRUE :144652  
```


## Using `data.table`  

```{r}
# Calculate total platform_length per student using data.table ----------------- 
dt_query_3 <- student_courses[,
                              .SD[1L],
                              by = .(id, platform, platform_start_date)] %>%
  .[, 
    .(total_days = sum(platform_length),
      min_days = min(platform_length),
      median_days = median(platform_length),  
      max_days = max(platform_length)),
    keyby = id]

summary(setDT(dplyr_query_3) == dt_query_3)
#>     id          total_days     min_days       median_days    max_days      
#>  Mode:logical   Mode:logical   Mode:logical   Mode:logical   Mode:logical  
#>  TRUE:144676    TRUE:144676    TRUE:144676    TRUE:144676    TRUE:144676  
```


## Benchmark data operations     

The `data.table` solutions are significantly faster as group by operations are required.   

```{r, echo=FALSE, results='markup'}
# Benchmark dplyr and data.table functions -------------------------------------  
if (!file.exists(here("data", "data-table-benchmarks-2", "query2.rds"))) {
  
  query1 <- microbenchmark(dplyr_query_2_funs = student_courses %>%
                             group_by(id) %>%  
                             summarise(total_days = sum(platform_length),
                                       min_days = min(platform_length),
                                       median_days = median(platform_length),  
                                       max_days = max(platform_length)) %>%
                             ungroup(),
                           dt_query_2_funs = student_courses[, 
                                                             .(total_days = sum(platform_length),
                                                               min_days = min(platform_length),
                                                               median_days = median(platform_length),  
                                                               max_days = max(platform_length)),
                                                             by = id]  ,
                           dplyr_query_3_funs = student_courses %>%
                             group_by(id, platform, platform_start_date) %>%
                             filter(row_number() == 1L) %>%
                             ungroup() %>%
                             group_by(id) %>%  
                             summarise(total_days = sum(platform_length),
                                       min_days = min(platform_length),
                                       median_days = median(platform_length),  
                                       max_days = max(platform_length)) %>%
                             ungroup(), 
                           dt_query_3_funs = student_courses[,
                                                             .SD[1L],
                                                             by = .(id, platform, platform_start_date)] %>%
                             .[, 
                               .(total_days = sum(platform_length),
                                 min_days = min(platform_length),
                                 median_days = median(platform_length),  
                                 max_days = max(platform_length)),
                               keyby = id],
                           times = 25) 
  
  saveRDS(query1, here("data", "data-table-benchmarks-2", "query2.rds"))
}

# Print summary table ----------------------------------------------------------
query2 <- readRDS(here("data", "data-table-benchmarks-2", "query2.rds"))
knitr::kable(summary(query2), caption = "Units: milliseconds")   
```


# Summarise multiple variables   

Imagine that you are interested in how the length of time spent on a platform varies per student per platform. This involves a similar two-stage step to the one above, except that transformations are specifically applied to selective variable(s):     

+ First, group by `id`, `platform`, `platform_start_date` and extract the first row of each group.  
+ Next, group by `id` and `platform`, select variables of interest and apply the required transformation/ aggregation.   


## Using `dplyr`    

In `dplyr`, this is facilitated by using `across()` inside `summarise()`, which allows you to perform the same list of statistical calculations of a single or multiple columns.    

```{r}
# Remove duplicate rows and summarise across platform_length using dplyr ------- 
dplyr_query_4 <- student_courses %>%
  group_by(id, platform, platform_start_date) %>%
  filter(row_number() == 1L) %>%
  ungroup() %>%
  group_by(id, platform) %>%  
  summarise(across(contains("length"),
                   list(mean = mean, sd = sd)),
            .groups = "drop") # Replaces the need to ungroup() after summarise() 
```


## Using `data.table`   

In `data.table`, the equivalent method is to specify variable(s) of interest using `.SDcols` and perform `lapply(.SD, ...)`.    

```{r}
# Remove duplicate rows and lapply() across platform_length using data.table ---
# Solution 1  
dt_query_4_1 <- student_courses[,
                              .SD[1L],
                              by = .(id, platform, platform_start_date)] %>%
  .[, 
    unlist(lapply(.SD,
                  function(x) list(mean = mean(x),
                                   sd = sd(x))),
           recursive = F),
    .SDcols = grep("length", colnames(student_courses)),
    keyby = .(id, platform)]

# Solution 2
```


## Benchmark data operations     

```{r, echo=FALSE, results='markup'}

```


# Use `lag` operations    


## Using `data.table`  

```{r}

```


## Using `data.table`  

```{r}

```


## Benchmark data operations     

```{r}

```


# Other resources      

+ A great side-by-side comparison of `data.table` versus `dplyr` functions from a [blog post by Atrebas](https://atrebas.github.io/post/2019-03-03-datatable-dplyr/).           

+ A list of advanced `data.table` operations and tricks from a [blog post by Andrew Brooks](http://brooksandrew.github.io/simpleblog/articles/advanced-data-table/).    

+ A [stack overflow discussion](https://stackoverflow.com/questions/61322864/is-there-a-visual-explanation-of-why-data-table-operations-are-faster-than-tidyv) about why group by operations are much faster using `data.table`.      